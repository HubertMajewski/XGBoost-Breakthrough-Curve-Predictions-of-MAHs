

```{r}
#Load libraries
pacman::p_load(tidyverse, magrittr, gdata, skimr, pracma, data.table, testthat, numbers, xgboost, mlr, optimx, parallel, parallelMap, doParallel, doSNOW, foreach, beepr)

#Set memory limitations
memory.limit(size = 32 * 1024 + 64 * 1024) # Where 64 is paging file size in GB

#Set the current working directory (to pull data etc.)
setwd("./")

#Set read directory
readDirectory <- getwd()

#Set save directory (normally the current directory)
saveDirectory <- getwd()

#Get number of processor threads for RStudio to use when generating models, or other of R's internals
cores <- ifelse(is.na(detectCores()) || detectCores() < 2, 3 - 1, detectCores() - 2)
coreCluster <- parallel::makeCluster(cores, outfile="")
doParallel::registerDoParallel(coreCluster, cores = cores)

#Project modeling control flags
transformFunction = TRUE #Apply transformations

#Pull data
xgb <- data.table(fread(paste(readDirectory, "/data.csv", sep = "")))
xgb = xgb %>% select(-V, -D) # Optim data to pull (include V and D for computations)
  
#Remove trailing whitespace from tracer names
xgb[, Tracer := trim(Tracer)]

#Set default transformation function (keep original data)
transformation <- function(x) {return (x)}
inverseTransformation <- function(x) {return (x)}
if (transformFunction) {
  
  #Case to prevent undefined when values are 1 for transformation function
  MAX_CONC = xgb[Tracer_Conc < 1 & Ogata < 1, .(Tracer_Conc, Ogata)] %>% as.matrix %>% max
  MIN_CONC = 1 - MAX_CONC
  #Recode 1's as a large number close to 1 same with 0 for transformation
  xgb[Tracer_Conc == 1, Tracer_Conc := MAX_CONC]
  xgb[Ogata == 1,       Ogata := MAX_CONC]
  xgb[Tracer_Conc == 0, Tracer_Conc := MIN_CONC]
  xgb[Ogata == 0,       Ogata := MIN_CONC]
  
  #Define the transformation function
  transformation <- function(x) {
    x <- replace(x, x == 1, MAX_CONC)
    x <- replace(x, x == 0, MIN_CONC)
    ans <- log(x / (1 - x))
    return (ans)
  }
  inverseTransformation <- function(x) {
    x <- replace(x, x > 500, 500)
    ans <- exp(x) / (1 + exp(x))
    return (ans)
  }
  
  #Transform concentrations for predictions
  xgb[, Tracer_Conc := transformation(Tracer_Conc)]
  xgb[, Ogata :=       transformation(Ogata)]
  
}

#Deterministic seed
set.seed(65535)

```

```{r}
#Error Functions
SSEfunc <- function(data) {
  data <- data.table(Time=data$Time, Pred=data$Pred, Tracer_Conc=data$Tracer_Conc)
  data[,Tracer_Conc := (Tracer_Conc)]
  
  #Enforce order by time incase aded by groups of tracers (out of order)
  data <- data[order(data$Time), ]
  
  #Uniform times
  dt <- 0.1
  times <- seq(from = 0, to = as.numeric(max(data$Time)), by = dt)
  
  #For each point compute the prediction
  error = 0
  for(x in times) {
    x1 <- data[Time < x, ]
    if (nrow(x1) == 0) {
      y1 <- 0
      yhat1 <- 0
      x1 <- 0
    } else {
      x1 <- x1[length(x1), ]
      y1 <- x1$Tracer_Conc
      yhat1 <- x1$Pred
      x1 <- x1$Time
    }
    
    x2 <- data[Time >= x, ]
    if (nrow(x2) == 0) { #Done, no more points on right 
      break
    } else {
      x2 <- x2[1, ]
      y2 <- x2$Tracer_Conc
      yhat2 <- x2$Pred
      x2 <- x2$Time
    }
    
    Pred <- (yhat2 - yhat1) / (x2 - x1) * (x - x2) + yhat2
    Conc <- (y2 - y1) / (x2 - x1) * (x - x2) + y2
    
    error <- error + ifelse(is.na((Conc - Pred) ^ 2 * dt), 0, (Conc - Pred) ^ 2 * dt)
  }
  
  return(error)
  
}

MSEfunc <- function(data) {
  data <- data.table(Time=data$Time, Pred=data$Pred, Tracer_Conc=data$Tracer_Conc)
  data[,Tracer_Conc := (Tracer_Conc)]
  
  #g_MSE <-
  #mean((
  #  inverseTransformation(y_test) - inverseTransformation(oos_predictions[[tracer]]$Pred)
  #) ^ 2)
  
  #Enforce order by time incase added by groups of tracers (out of order)
  data <- data[order(data$Time), ]
  
  #Uniform times
  dt <- 0.1
  times <- seq(from = 0, to = as.numeric(max(data$Time)), by = dt)
  
  #For each point compute the prediction
  total = 0
  error = 0
  for(x in times) {
    x1 <- data[Time < x, ]
    if (nrow(x1) == 0) {
      y1 <- 0
      yhat1 <- 0
      x1 <- 0
    } else {
      x1 <- x1[length(x1), ]
      y1 <- x1$Tracer_Conc
      yhat1 <- x1$Pred
      x1 <- x1$Time
    }
    
    x2 <- data[Time >= x, ]
    if (nrow(x2) == 0) { #Done, no more points on right 
      break
    } else {
      x2 <- x2[1, ]
      y2 <- x2$Tracer_Conc
      yhat2 <- x2$Pred
      x2 <- x2$Time
    }
    
    Pred <- (yhat2 - yhat1) / (x2 - x1) * (x - x2) + yhat2
    Conc <- (y2 - y1) / (x2 - x1) * (x - x2) + y2
    
    error <- error + ifelse(is.na((Conc - Pred) ^ 2 * dt), 0, (Conc - Pred) ^ 2 * dt)
    total <- total + 1
  }
  
  return(error / total)
  
}

SSTfunc <- function(data) {
  data <- data.table(Time=data$Time, Pred=data$Pred, Tracer_Conc=data$Tracer_Conc)
  data[,Tracer_Conc := (Tracer_Conc)]
  
  #g_SST <-
  #sum((
  #  inverseTransformation(y_test) - mean(inverseTransformation(y_test))
  #) ^ 2)
  
  #Enforce order by time incase added by groups of tracers (out of order)
  data <- data[order(data$Time), ]
  
  #Uniform times
  dt <- 0.1
  times <- seq(from = 0, to = as.numeric(max(data$Time)), by = dt)
  
  #For each point compute the prediction
  error = 0
  total = 0
  Pred = 0
  Conc <- as.vector(x = 0, mode = "numeric")
  for(x in times) {
    x1 <- data[Time < x, ]
    if (nrow(x1) == 0) {
      y1 <- 0
      yhat1 <- 0
      x1 <- 0
    } else {
      x1 <- x1[length(x1), ]
      y1 <- x1$Tracer_Conc
      yhat1 <- x1$Pred
      x1 <- x1$Time
    }
    
    x2 <- data[Time >= x, ]
    if (nrow(x2) == 0) { #Done, no more points on right 
      break
    } else {
      x2 <- x2[1, ]
      y2 <- x2$Tracer_Conc
      yhat2 <- x2$Pred
      x2 <- x2$Time
    }
    
    Pred <- Pred + ifelse(is.na((yhat2 - yhat1) / (x2 - x1) * (x - x2) + yhat2) , 0, (yhat2 - yhat1) / (x2 - x1) * (x - x2) + yhat2)
    Conc <- append(Conc, (y2 - y1) / (x2 - x1) * (x - x2) + y2)
    total <- total + 1
  }
  Pred <- Pred / total
  error <- sapply(Conc, function(x) {ifelse(is.na((x - Pred) ^ 2 * dt), 0, (x - Pred) ^ 2 * dt)})
  
  return(sum(error))
  
}

```


```{r}
#LOO by Tracer
uniquetracers = unique(xgb$Tracer)

results = list()
coreCluster <- makeCluster(cores, outfile="")
registerDoSNOW(coreCluster)
textProgressBar <- txtProgressBar(max=length(uniquetracers), style = 3)
progressBar <- list(progress = function(n) setTxtProgressBar(textProgressBar, n))
results = foreach(tracer = uniquetracers, .combine = c, .init = NULL, .packages = .packages(), .inorder = TRUE, .multicombine = TRUE, .verbose = F, .options.snow = progressBar) %dopar% #dopar
  {
    
    #Train and Test
    #LOO Split via tracer
    x_train = xgb[Tracer != tracer, ]
    x_test = xgb[Tracer == tracer, ]
    y_train = x_train$Tracer_Conc
    y_test = x_test$Tracer_Conc
    
    #Get initial coefficients
    g_mod = lm(y_train ~ 
                 (Time) * 
                 (Ogata) *
                 (A + Y + K + P + G + H + C + Q + W + J + S + R),
               x_train[, c("Time", "Ogata", "A", "Y", "K", "P", "G", "H", "C", "Q", "W", "J", "S", "R")]) # The letters are placeholders for our features
    
    #Save predictions for the current tracer not of all tracers
    is_predictions =
      data.table(
        "Tracer_Conc" = as.vector(inverseTransformation(y_train), mode= "numeric"),
        "Pred" = as.vector(inverseTransformation(predict(g_mod, x_train[ , !"Tracer"])), mode= "numeric"),
        "Tracer" = x_train$Tracer,
        "Time" = as.vector(x_train$Time, mode= "numeric")
      )
    oos_predictions =
      data.table(
        "Tracer_Conc" = as.vector(inverseTransformation(y_test), mode= "numeric"),
        "Pred" = as.vector(inverseTransformation(predict(g_mod, x_test[ , !"Tracer"])), mode= "numeric"),
        "Tracer" = x_test$Tracer,
        "Time" = as.vector(x_test$Time, mode= "numeric")
      )
    
    #Compute Errors
    g_MSE = MSEfunc(oos_predictions)
    g_SSE = SSEfunc(oos_predictions)
    IS_g_SSE = SSEfunc(is_predictions)
    g_SST = SSTfunc(oos_predictions)
    g_R2  = 1 - (g_SSE / g_SST)
    g_RMSE = sqrt(g_MSE)
    
    #Save metrics
    R2   = g_R2
    SSE  = g_SSE
    RMSE = g_RMSE
    MSE  = g_MSE
    
    #Add model to the list of models made for each tracer dynamically
    models = g_mod
    
    #Return computations for tracer as results
    results = ifelse(!exists("results"), list(), results)
    results[[tracer]] = list(Tracer = tracer, R2 = R2, SSE = SSE, IS_SSE = IS_g_SSE, RMSE = RMSE, MSE = MSE, model = g_mod, is_predictions = is_predictions, oos_predictions = oos_predictions) #, x_test_cpy = x_test_cpy, x_train_cpy = x_train_cpy, y_test_cpy = y_test_cpy, y_train_cpy = y_train_cpy)
    
    #Cleanup unused data as it is saved. Reduces a lot of memory usage.
    rm("is_predictions", "oos_predictions", "x_test", "x_train", "y_test", "y_train")
    invisible(gc())
    
    return(results)
  } # for tracer
close(textProgressBar)
stopCluster(coreCluster)

#Cleanup
gc()
```


```{r}
#Undo transformations for comparison
xgb[, Tracer_Conc := inverseTransformation(Tracer_Conc)]
xgb[, Ogata :=       inverseTransformation(Ogata)]
```

```{r, eval = TRUE}
#Set save directory
setwd(saveDirectory)

#Save the environment upon completion (takes a bit)
savePath <- paste(getwd(), "/result.Rdata", sep = "")
if(file.exists(savePath))
  file.remove(savePath)
save.image(savePath)

#Save all of the models created
savePath <- paste(getwd(), "/models/", sep = "")
if (!dir.exists(savePath)) dir.create(savePath)
for (tracer in uniquetracers) {
   
    
    savePath <- paste(getwd(), "/models/", tracer, ".LM", sep = "")
    
    if (file.exists(savePath))
      file.remove(savePath)
    
    sink(savePath)
    print(results[[tracer]]$model)
    sink()
  
}

#Scream for attention. Ideal when using MLR for forest after long wait times.
print("Completed and Saved Successfully.")
scream = FALSE
beep(10)
```